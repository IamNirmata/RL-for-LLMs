# This script creates a zip archive containing the step-by-step README and Python code
# so the user can download everything in one click.

import os
import zipfile
from pathlib import Path

base_dir = Path("/mnt/data/verl_ppo_grpo_101")
base_dir.mkdir(parents=True, exist_ok=True)

# File contents
readme = """# verl PPO / GRPO 101 (Step-by-Step)

This package teaches you how to train a small LLM using PPO and GRPO with **verl**.

## What you will learn
1. How to prepare a parquet dataset for RL
2. How to write a custom reward function
3. How PPO works in practice
4. How GRPO differs from PPO (no critic, group-based baseline)
5. How to switch PPO â†’ GRPO with minimal config changes

## Order of execution
1. Install verl
2. Run prepare_toy_parquet.py
3. Run train_with_verl.py with --algo ppo
4. Run train_with_verl.py with --algo grpo

See comments inside each Python file for detailed explanations.
"""

prepare_data = """\
# prepare_toy_parquet.py
import os
import pandas as pd

def main():
    os.makedirs("data", exist_ok=True)

    rows = [
        {"prompt": "Return JSON with answer and explanation. What is 2+2?", "ground_truth": "4", "data_source": "toy"},
        {"prompt": "Return JSON with answer and explanation. What is 3+5?", "ground_truth": "8", "data_source": "toy"},
        {"prompt": "Return JSON with answer and explanation. What is 10-7?", "ground_truth": "3", "data_source": "toy"},
    ]

    df = pd.DataFrame(rows)
    df.to_parquet("data/toy_train.parquet", index=False)
    df.to_parquet("data/toy_val.parquet", index=False)

    print("Parquet files written to ./data")

if __name__ == "__main__":
    main()
"""

reward_code = """\
# my_reward.py
import json

def compute_score(data_source, solution_str, ground_truth, extra_info=None):
    try:
        obj = json.loads(solution_str.strip())
    except Exception:
        return 0.0

    if "answer" not in obj:
        return 0.0

    if str(obj["answer"]).strip() == str(ground_truth).strip():
        return 1.0
    return 0.1
"""

train_code = """\
# train_with_verl.py
import argparse
import subprocess

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--algo", choices=["ppo", "grpo"], required=True)
    parser.add_argument("--model", required=True)
    args = parser.parse_args()

    cmd = [
        "python", "-m", "verl.trainer.main_ppo",
        "data.train_files=data/toy_train.parquet",
        "data.val_files=data/toy_val.parquet",
        f"actor_rollout_ref.model.path={args.model}",
        "custom_reward_function.path=rewards/my_reward.py",
    ]

    if args.algo == "grpo":
        cmd += [
            "algorithm.adv_estimator=grpo",
            "actor_rollout_ref.rollout.n=4",
            "actor_rollout_ref.actor.use_kl_loss=True",
        ]

    subprocess.run(cmd, check=True)

if __name__ == "__main__":
    main()
"""

# Write files
(base_dir / "README.md").write_text(readme)
(base_dir / "prepare_toy_parquet.py").write_text(prepare_data)
(base_dir / "train_with_verl.py").write_text(train_code)

rewards_dir = base_dir / "rewards"
rewards_dir.mkdir(exist_ok=True)
(rewards_dir / "my_reward.py").write_text(reward_code)

# Zip everything
zip_path = "/mnt/data/verl_ppo_grpo_101.zip"
with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as z:
    for file in base_dir.rglob("*"):
        z.write(file, arcname=file.relative_to(base_dir))

zip_path
